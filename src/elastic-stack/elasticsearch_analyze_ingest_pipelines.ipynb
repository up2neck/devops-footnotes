{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bda0531-ff6d-42ab-9503-4136f0e5924d",
   "metadata": {},
   "source": [
    "# Analyze Elasticsearch ingest pipelines\n",
    "\n",
    "The notebook gives insights to index templates:\n",
    "- Obsolete/Deprecated ingest pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a4c7b-f488-436a-9d2e-a6d882ca9185",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0141c-fac8-42cc-b79b-5fcf593c8e1f",
   "metadata": {},
   "source": [
    "### Install required Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd1676-515c-418d-bff6-5edeeb1df789",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas~=2.2 elasticsearch~=8.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec908d-3b62-4d77-8d0b-15f6579919d8",
   "metadata": {},
   "source": [
    "### Restart Jupiter kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4241ab-7895-4852-80a0-0eb8753c130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada0f1f-7226-4a14-9461-317b43f2f370",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d1dba-a2e3-4d40-8a89-3deb1e58c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import time\n",
    "from pathlib import Path\n",
    "from elasticsearch import Elasticsearch\n",
    "from IPython.display import display, FileLink\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b57ea7-d1c9-4fc5-b282-8201c97ff152",
   "metadata": {},
   "source": [
    "### Input Elasticsearch connection settings\n",
    "\n",
    "To connect Elasticsearh instance it's hostname and valid API key are required.\n",
    "\n",
    "API key can be created via Kibana - [https://www.elastic.co/guide/en/kibana/current/api-keys.html](https://www.elastic.co/guide/en/kibana/current/api-keys.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc02ebe-3b6e-4717-b970-efeb7c6684b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticsearch_host = input(\"Enter Elasticsearch hostname: \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd158946-88b3-461d-a9cc-68f96af0c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticsearch_api_key = getpass.getpass(\"Enter Elasticsearch API key: \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5933a18-3e0e-443e-b40a-4fe5966e2c64",
   "metadata": {},
   "source": [
    "### Create Elasticsearch client and connect the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36447c-2f09-4346-a32a-bf34b0c6b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(\n",
    "    hosts=elasticsearch_host,\n",
    "    api_key=elasticsearch_api_key,\n",
    "    verify_certs=False,             # Elasticsearch certificate is signed by the non-public authority, so ignore any warning\n",
    "    ssl_show_warn=False             # Unverified SSL/TLS connections cause a lot of warnings, so them should be supressed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64c3bf-1260-4a7f-b50a-915424a0da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.cat.health())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f9c37-c993-4a9e-8565-0f2739ddc415",
   "metadata": {},
   "source": [
    "## Analyze ingest pipelines in the cluster\n",
    "\n",
    "### Find unused ingest pipelines\n",
    "\n",
    "> **WARNING**: all of the steps below must be proceeded to ensure correctness of results\n",
    "\n",
    "#### Determine ingest pipelines referenced by the index and component templates\n",
    "\n",
    "First places where to look for ingest pipelines usage are index and component templates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42540ba7-df93-4e4e-a83e-672b39fe2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is helper used in several blocks, so it's necessary to execute it\n",
    "# Get ingest pipelines from index settings\n",
    "def extract_pipelines_from_settings(settings):\n",
    "    \"\"\"\n",
    "    Extract pipeline names from settings dictionary.\n",
    "\n",
    "    Args:\n",
    "    settings (dict): Settings dictionary from a template.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of pipeline names.\n",
    "    \"\"\"\n",
    "    default_pipeline = settings.get(\"index\", {}).get(\"default_pipeline\", \"\")\n",
    "    final_pipeline = settings.get(\"index\", {}).get(\"final_pipeline\", \"\")\n",
    "    \n",
    "    pipelines = []\n",
    "    if default_pipeline != \"\":\n",
    "        pipelines.append(default_pipeline)\n",
    "    if final_pipeline != \"\":\n",
    "        pipelines.append(final_pipeline)\n",
    "\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea70ad-2957-451a-9603-dd4d8dc39ebb",
   "metadata": {},
   "source": [
    "The code below extracts ingest pipelines names are referenced in index and component templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35259894-5a71-454d-a308-85f4718a88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ingest pipelines referenced by index or component templates\n",
    "def pipelines_from_templates(client, template_type):\n",
    "    \"\"\"\n",
    "    Fetch ingest pipelines referenced by index or component templates.\n",
    "\n",
    "    Args:\n",
    "    client (Elasticsearch): Elasticsearch client instance.\n",
    "    template_type (str): Type of template, either 'index' or 'component'.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of pipeline names.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the template_type is not one of 'index' or 'component'.\n",
    "    \"\"\"\n",
    "    if template_type not in [\"index\", \"component\"]:\n",
    "        raise ValueError(\"template_type must be one of: 'index', 'component'.\")\n",
    "        \n",
    "    if template_type == \"component\":\n",
    "        response = client.cluster.get_component_template()\n",
    "    else:\n",
    "        response = client.indices.get_index_template()\n",
    "\n",
    "    # Extract templates from the response\n",
    "    templates = response[f\"{template_type}_templates\"]\n",
    "    \n",
    "    pipelines = []\n",
    "    for template in templates:\n",
    "        settings = template.get(f\"{template_type}_template\", {}).get(\"template\", {}).get(\"settings\", {})\n",
    "        pipelines.extend(extract_pipelines_from_settings(settings))\n",
    "\n",
    "    return pipelines\n",
    "\n",
    "pipelines = pipelines_from_templates(client, \"index\") + pipelines_from_templates(client, \"component\")\n",
    "# Deduplicate pipelines\n",
    "unique_pipelines_in_templates = list(set(pipelines))\n",
    "print(f\"There are {len(unique_pipelines_in_templates)} unique pipelines referenced by templates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ff888-8cbc-4803-b55b-84b18ffefe6b",
   "metadata": {},
   "source": [
    "#### Determine ingest pipelines that are referenced by existing indices.\n",
    "\n",
    "> **WARNING**: the execution of code below could take a long time, depending on the number of indices in cluster. Note the batch loop behavior which adds sleep after loop and might be adjusted.\n",
    "\n",
    "It might be achieved with in, at least, 2 ways:\n",
    "- By using the indices API to query an Elasticsearch cluster for all indices, e.g., GET /*.\n",
    "- By using the cat API to query for index names from the cluster, and then retrieving indices configuration in a batch manner.\"\n",
    "\n",
    "The code below uses the second way to avoid heavy requests to Elasticsearch cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1985f-2ec6-4075-8f7e-2c4b485be1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_names(client):\n",
    "    \"\"\"\n",
    "    Retrieve the names of all indices in the Elasticsearch cluster.\n",
    "\n",
    "    Args:\n",
    "    client (Elasticsearch): The Elasticsearch client instance.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of index names.\n",
    "    \"\"\"\n",
    "    response = client.cat.indices(expand_wildcards=\"all\", format=\"json\", h=\"index\")\n",
    "    return [index[\"index\"] for index in response]\n",
    "\n",
    "def batch(sequence, batch_size=1):\n",
    "    \"\"\"\n",
    "    Generate batches of a specified size from a sequence.\n",
    "\n",
    "    Args:\n",
    "    sequence (list): The sequence to batch.\n",
    "    batch_size (int): The size of each batch.\n",
    "\n",
    "    Yields:\n",
    "    list: A batch from the sequence.\n",
    "    \"\"\"\n",
    "    length = len(sequence)\n",
    "    for start_index in range(0, length, batch_size):\n",
    "        yield sequence[start_index:min(start_index + batch_size, length)]\n",
    "\n",
    "indices_names = get_indices_names(client)\n",
    "print(f\"There are {len(indices_names)} indices in cluster\")\n",
    "\n",
    "pipelines = []\n",
    "for indices_batch in batch(indices_names, 10):\n",
    "    response = client.indices.get(index=indices_batch, features=\"settings\")\n",
    "    for _, index_info in response.items():\n",
    "        pipelines.extend(extract_pipelines_from_settings(index_info[\"settings\"]))\n",
    "    time.sleep(0.05)  # Throttle requests to avoid overwhelming the server\n",
    "\n",
    "# Deduplicate pipelines\n",
    "unique_pipelines_in_indices = list(set(pipelines))\n",
    "print(f\"There are {len(unique_pipelines_in_indices)} unique pipelines referenced by indices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e860c2-5d99-41a7-916a-938b92848f46",
   "metadata": {},
   "source": [
    "#### Determine ingest pipelines that are referenced in ingest pipelines\n",
    "\n",
    "> NOTE: ingest pipelines may refer to non-existent pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6997e-e504-4e88-b34b-5a1877ffff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "response = client.ingest.get_pipeline()\n",
    "for _, pipeline_info in response.items():\n",
    "    for processor in pipeline_info[\"processors\"]:\n",
    "        if \"pipeline\" in processor:\n",
    "            pipelines.append(processor[\"pipeline\"][\"name\"])\n",
    "\n",
    "unique_pipelines_in_pipelines = list(set(pipelines))\n",
    "print(f\"There are {len(unique_pipelines_in_pipelines)} unique pipelines referenced by other ingest pipelines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c6b09-f367-4adf-9d65-2a1ec0bcb1f8",
   "metadata": {},
   "source": [
    "#### Analyze unused pipelines\n",
    "\n",
    "Process involves comparison of the ingest pipelines installed in cluster with the cumulative list of ingest pipelines referenced by:\n",
    "- Index and component templates\n",
    "- Existing indices\n",
    "- Other ingest pipelines\n",
    "\n",
    "Ingest pipelines installed in cluster but not referenced by an entity are compiled to CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401105e4-c347-4145-b3e7-2601691450d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_referenced_pipelines = list(set(\n",
    "    unique_pipelines_in_templates +\n",
    "    unique_pipelines_in_indices +\n",
    "    unique_pipelines_in_pipelines\n",
    "))\n",
    "print(f\"There are {len(unique_referenced_pipelines)} unique pipelines referenced in cluster.\")\n",
    "\n",
    "response = client.ingest.get_pipeline()\n",
    "pipelines_in_cluster = list(response.keys())\n",
    "print(f\"There are {len(pipelines_in_cluster)} total pipelines in the cluster.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e1ee0c-5bb4-4b7a-aa40-e05d7f653317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(pipelines_in_cluster, columns=[\"name\"])\n",
    "df2 = pd.DataFrame(unique_referenced_pipelines, columns=[\"name\"])\n",
    "\n",
    "diff = pd.merge(df1, df2, on=['name'], how='left', indicator=True)\n",
    "unused_pipelines = diff[diff['_merge'] == 'left_only']\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "output_dir = Path('temp')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = output_dir / \"obsolete_ingest_pipelines.csv\"\n",
    "unused_pipelines.to_csv(csv_path, index=False)\n",
    "\n",
    "# Display a link to download the CSV\n",
    "display(FileLink(csv_path, result_html_prefix=\"Open CSV file: \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
